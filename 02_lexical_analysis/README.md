# 02 · Lexical Analysis

문자 스트림을 **토큰(token)** 스트림으로 변환하는 스캐너의 개념을 정리했다.  
토큰 규칙은 **정규표현식(RE)** 으로 명세하고, 실제 인식은 (결국) **DFA**로 수행한다.  
겹치는 후보는 **Longest-Match**로 가장 긴 접두사를 택하고, 길이가 같으면 **규칙 선언 순서**가 우선한다.

---

## What I Learned
- **스캐너 ↔ 파서 경계**: 스캐너는 문자→토큰(공백/주석 제거, 어휘 오류 보고), 파서는 토큰→구문.
- **Token & Attribute**: 예) `INT(42)`, `ID(foo)`처럼 실제 값/이름을 속성으로 전달.
- **Regular Expressions**:  
  - 기본 연산: 합집합 `|`, 연접(concatenation), 반복 `*`(0회↑)  
  - 우선순위: `* > concat > |` (애매하면 괄호로 명시)  
  - 축약: `+`(1회↑), `?`(0/1회), `[a-z]`(문자 집합)
- **DFA 인식**: RE → (NFA) → DFA로 변환해 테이블-드리븐 방식으로 빠르게 스캔.
- **Longest-Match + 규칙 우선순위**:  
  - `return maybe != iffy;` → `RETURN  ID(maybe)  NEQ  ID(iffy)  SCOLON`  
  - `if`는 키워드(규칙 우선순위), `if8`은 식별자(더 긴 매치).

---

## Token Spec (Week 2 범위 요약)
- **키워드**: `return`, `if`
- **식별자**: `[A-Za-z_][A-Za-z0-9_]*` → `ID(name)`
- **정수 상수**: `[0-9]+` → `INT(42)`  
  (선행 0 금지를 원하면 `[1-9][0-9]*` 같은 정책으로 강화)
- **연산자/구분자**: `!=`, `>=`, `<=`, `==`, `=`, `;`, `(`, `)`
- **공백/주석**: `[ \t\r\n]+`, `--.*` → 무시(토큰 미방출)

> **설계 팁**  
> 1) 다문자 연산자를 단문자보다 **먼저** 선언(선언 순서 + Longest-Match).  
> 2) 키워드는 ID보다 **앞**에 둬서 `if`는 키워드, `if8/iffy`는 ID로 인식.

---

## Examples (입력·기대 출력)
`examples/` 폴더의 `.tig`(입력)과 `.tok`(기대 토큰)을 함께 보며 복습한다.

- `01_basic.tig` → `01_basic.tok`  
- `02_keywords_ids.tig` → `02_keywords_ids.tok`  
- `03_assignment.tig` → `03_assignment.tok`  
- `04_operators_parens.tig` → `04_operators_parens.tok`

> 주의: Week 2 범위에서는 **정수만** 다룬다(부동소수/지수형은 다음 주제에서 확장).

---

## Review Checklist
- [ ] RE 우선순위 `* > concat > |`를 암기했고 괄호로 명확히 쓸 수 있다.  
- [ ] `if`/`if8`/`iffy`가 왜 각각 **IF / ID / ID**가 되는지 설명할 수 있다.  
- [ ] `!=`이 `!` `=`로 쪼개지지 않게 설계하는 이유와 방법을 말할 수 있다.  
- [ ] 공백/주석을 어떻게 “토큰으로 방출하지 않고” 무시하는지 안다.

---

## Notes for Portfolio
- “Longest-Match 구현 감각”: 스캐너는 **마지막으로 accept였던 위치**를 기억했다가, 더 진행이 막히면 그 지점까지를 토큰으로 확정한다.  
- “규칙 우선순위”: 동일 길이 후보는 **사양에 먼저 선언된 규칙**을 선택한다(키워드 vs 식별자 처리에 필수).  
- 이어서 파싱(Bison)으로 확장 시, 현재의 사람이 읽기 좋은 출력 대신 **토큰 코드**를 반환하도록 변경하면 된다.

